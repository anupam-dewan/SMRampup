{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "420624a2-d42c-4d72-9bb3-3fb66acfddae",
   "metadata": {},
   "source": [
    "\n",
    "# What you will accomplish\n",
    "\n",
    "In this guide, you will:\n",
    "\n",
    "    - Build, train, and tune a model using script mode\n",
    "    - Detect bias in ML models and understand model predictions\n",
    "    - Deploy the trained model to a real-time inference endpoint for testing\n",
    "    - Evaluate the model by generating sample predictions and understanding feature impact\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac9e907-886d-4938-a4c4-324bd8893213",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bio: Josh, Data Scientist\n",
    "### Location: Bellevue, WA\n",
    "\n",
    "### Scenario:  \n",
    "\n",
    "Josh, is a data scientist at Figma Insurance who is working on training a binary classifier model that can predict fraudulent activity on insurance claims. Josh first uses SageMaker Studio with some python libraries to explore a dataset and finds some key characteristics that he can then use to engineer some features. Once he completes that, he decides to use XGboost framework to start training a base line model. This is exactly what you will start actioning on in this tutorial. You will use XGBoost and Panda Libraries to start training a base line model and do some experimentation and model tuning with various parameters using SM Hyperparameter. \n",
    "\n",
    "Next, Josh will check to see if the model has any underlying bias that could cause the model to be impartial against certain facets like gender, race, and other demographics using SM Clarify. he also realizes that he needs to have an explainability around her model for why did the model predict something. What caused the model to make certain predictions? using SM Explainability Reports. After Josh completes bias and explainability checks, he is ready to deploy the model on a staging environment using SM Endpoints. Then he finishes up by conducting some inference test calls to understand how the model performs on a new unseen dataset. Once that is complete, he terminates her endpoints.\n",
    "\n",
    "Six months later her new teammate, Christina, sees a deprecation in the performance of the deployed model which leads him to believe that the model might need to go through a re-training process. Thanks to SM pipeline, Josh can easily retrain the whole model using a new data with just a click of a button. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc102566-c6d6-41cd-8e8c-748bb4d3a380",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 2: Set up a SageMaker Studio notebook ( library installation & variable settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126f415a-81cd-4abc-b68b-954a253da387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.6 which is incompatible.\n",
      "sagemaker 2.143.0 requires importlib-metadata<5.0,>=1.4.0, but you have importlib-metadata 6.1.0 which is incompatible.\n",
      "sagemaker 2.143.0 requires PyYAML==5.4.1, but you have pyyaml 6.0 which is incompatible.\n",
      "sagemaker-data-insights 0.3.3 requires pandas>=1.1.4, but you have pandas 1.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q  xgboost==1.3.1 pandas==1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5869a439-c045-4911-8498-3bbb87b606db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (1.26.103)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.103 in /opt/conda/lib/python3.7/site-packages (from boto3) (1.29.103)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.103->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.103->boto3) (1.26.15)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.103->boto3) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc056bbe-eeac-4f16-bfc5-3fc496d7e93f",
   "metadata": {},
   "source": [
    "### NOTE: Please change your alias here as this will help us not intermix multiple users logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3424a1c2-def1-47a3-ba04-9f3d85e7993e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alias ='dewanup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ccff1a8-3213-4a49-a738-f9af5909338c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import joblib\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner\n",
    ")\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "# Setting SageMaker variables\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo-\"+alias\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\" \n",
    "\n",
    "\n",
    "# Setting S3 location for read and write operations\n",
    "train_data_key = f\"{read_prefix}/train.csv\"\n",
    "test_data_key = f\"{read_prefix}/test.csv\"\n",
    "validation_data_key = f\"{read_prefix}/validation.csv\"\n",
    "model_key = f\"{write_prefix}/model\"\n",
    "output_key = f\"{write_prefix}/output\"\n",
    "\n",
    "\n",
    "train_data_uri = f\"s3://{read_bucket}/{train_data_key}\"\n",
    "test_data_uri = f\"s3://{read_bucket}/{test_data_key}\"\n",
    "validation_data_uri = f\"s3://{read_bucket}/{validation_data_key}\"\n",
    "model_uri = f\"s3://{write_bucket}/{model_key}\"\n",
    "output_uri = f\"s3://{write_bucket}/{output_key}\"\n",
    "estimator_output_uri = f\"s3://{write_bucket}/{write_prefix}/training_jobs\"\n",
    "bias_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify-output/bias\"\n",
    "explainability_report_output_uri = f\"s3://{write_bucket}/{write_prefix}/clarify-output/explainability\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c29c0e43-1163-4ea7-ba3b-196312f73fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_job_name_prefix = \"xgbtune-\" +alias\n",
    "training_job_name_prefix = \"xgbtrain-\"+alias\n",
    "\n",
    "xgb_model_name = \"fraud-detect-xgb-model-\" +alias\n",
    "endpoint_name_prefix = \"xgb-fraud-model-dev-\"+alias\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.m4.xlarge\"\n",
    "predictor_instance_count = 1\n",
    "predictor_instance_type = \"ml.m4.xlarge\"\n",
    "clarify_instance_count = 1\n",
    "clarify_instance_type = \"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a420d-1315-401a-941e-90da66420c15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 3: Develop and get a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4229500d-0e3b-4d3a-9970-2d09c52c6d10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xgboost_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile xgboost_train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters and algorithm parameters are described here\n",
    "    parser.add_argument(\"--num_round\", type=int, default=50)\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=2)\n",
    "    parser.add_argument(\"--eta\", type=float, default=0.2)\n",
    "    parser.add_argument(\"--subsample\", type=float, default=0.6)\n",
    "    parser.add_argument(\"--colsample_bytree\", type=float, default=0.6)\n",
    "    parser.add_argument(\"--objective\", type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument(\"--eval_metric\", type=str, default=\"auc\")\n",
    "    parser.add_argument(\"--nfold\", type=int, default=3)\n",
    "    parser.add_argument(\"--early_stopping_rounds\", type=int, default=3)\n",
    "    \n",
    "\n",
    "    # SageMaker specific arguments. Defaults are set in the environment variables\n",
    "    # Location of input training data\n",
    "    parser.add_argument(\"--train_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    # Location of input validation data\n",
    "    parser.add_argument(\"--validation_data_dir\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    # Location where trained model will be stored. Default set by SageMaker, /opt/ml/model\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    # Location where model artifacts will be stored. Default set by SageMaker, /opt/ml/output/data\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    data_train = pd.read_csv(f\"{args.train_data_dir}/train.csv\")\n",
    "    train = data_train.drop(\"fraud\", axis=1)\n",
    "    label_train = pd.DataFrame(data_train[\"fraud\"])\n",
    "    dtrain = xgb.DMatrix(train, label=label_train)\n",
    "    \n",
    "    \n",
    "    data_validation = pd.read_csv(f\"{args.validation_data_dir}/validation.csv\")\n",
    "    validation = data_validation.drop(\"fraud\", axis=1)\n",
    "    label_validation = pd.DataFrame(data_validation[\"fraud\"])\n",
    "    dvalidation = xgb.DMatrix(validation, label=label_validation)\n",
    "\n",
    "    params = {\"max_depth\": args.max_depth,\n",
    "              \"eta\": args.eta,\n",
    "              \"objective\": args.objective,\n",
    "              \"subsample\" : args.subsample,\n",
    "              \"colsample_bytree\":args.colsample_bytree\n",
    "             }\n",
    "    \n",
    "    num_boost_round = args.num_round\n",
    "    nfold = args.nfold\n",
    "    early_stopping_rounds = args.early_stopping_rounds\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        metrics=[\"auc\"],\n",
    "        seed=42,\n",
    "    )\n",
    "    \n",
    "    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=len(cv_results))\n",
    "    \n",
    "    train_pred = model.predict(dtrain)\n",
    "    validation_pred = model.predict(dvalidation)\n",
    "    \n",
    "    train_auc = roc_auc_score(label_train, train_pred)\n",
    "    validation_auc = roc_auc_score(label_validation, validation_pred)\n",
    "    \n",
    "    print(f\"[0]#011train-auc:{train_auc:.2f}\")\n",
    "    print(f\"[0]#011validation-auc:{validation_auc:.2f}\")\n",
    "\n",
    "    metrics_data = {\"hyperparameters\" : params,\n",
    "                    \"binary_classification_metrics\": {\"validation:auc\": {\"value\": validation_auc},\n",
    "                                                      \"train:auc\": {\"value\": train_auc}\n",
    "                                                     }\n",
    "                   }\n",
    "              \n",
    "    # Save the evaluation metrics to the location specified by output_data_dir\n",
    "    metrics_location = args.output_data_dir + \"/metrics.json\"\n",
    "    \n",
    "    # Save the model to the location specified by model_dir\n",
    "    model_location = args.model_dir + \"/xgboost-model\"\n",
    "\n",
    "    with open(metrics_location, \"w\") as f:\n",
    "        json.dump(metrics_data, f)\n",
    "\n",
    "    with open(model_location, \"wb\") as f:\n",
    "        joblib.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b064808-5c80-4f66-8403-6315a6a3901e",
   "metadata": {},
   "source": [
    "# Step 4: Train a base line model first using SageMaker Training Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7548661-44cd-44dd-a6ae-07eb50f1ceed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m4.xlarge.\n",
      "INFO:sagemaker:Creating training-job with name: xgbtrain-dewanup-2023-04-03-06-06-39-282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-03 06:06:40 Starting - Starting the training job...\n",
      "2023-04-03 06:07:05 Starting - Preparing the instances for training......\n",
      "2023-04-03 06:08:12 Downloading - Downloading input data...\n",
      "2023-04-03 06:08:37 Training - Downloading the training image.....\u001b[34m[2023-04-03 06:09:33.749 ip-10-2-127-225.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-04-03 06:09:33.778 ip-10-2-127-225.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:33:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:33:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:33:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:33:INFO] Module xgboost_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:33:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:33:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:33:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: xgboost-train\n",
      "  Building wheel for xgboost-train (setup.py): started\n",
      "  Building wheel for xgboost-train (setup.py): finished with status 'done'\n",
      "  Created wheel for xgboost-train: filename=xgboost_train-1.0.0-py2.py3-none-any.whl size=5100 sha256=f19987179a1cf5a2ceb777550a76989bbfd3c6213056b3831364d96a60ca53f5\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-fhc8nw4w/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built xgboost-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xgboost-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed xgboost-train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:36:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2023-04-03:06:09:36:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"xgbtrain-dewanup-2023-04-03-06-06-39-282\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-539179515961/fraud-detect-demo-dewanup/training_jobs/xgbtrain-dewanup-2023-04-03-06-06-39-282/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"xgboost_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"xgboost_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=xgboost_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=xgboost_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-539179515961/fraud-detect-demo-dewanup/training_jobs/xgbtrain-dewanup-2023-04-03-06-06-39-282/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"xgbtrain-dewanup-2023-04-03-06-06-39-282\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-539179515961/fraud-detect-demo-dewanup/training_jobs/xgbtrain-dewanup-2023-04-03-06-06-39-282/source/sourcedir.tar.gz\",\"module_name\":\"xgboost_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"xgboost_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m xgboost_train\u001b[0m\n",
      "\u001b[34m[06:09:37] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.87\u001b[0m\n",
      "\u001b[34m[0]#011validation-auc:0.83\u001b[0m\n",
      "\n",
      "2023-04-03 06:09:43 Uploading - Uploading generated training model\n",
      "2023-04-03 06:09:55 Completed - Training job completed\n",
      "Training seconds: 102\n",
      "Billable seconds: 102\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator_base = XGBoost(\n",
    "                        entry_point=\"xgboost_train.py\",\n",
    "                        output_path=estimator_output_uri,\n",
    "                        code_location=estimator_output_uri,\n",
    "                        role=sagemaker_role,\n",
    "                        instance_count=train_instance_count,\n",
    "                        instance_type=train_instance_type,\n",
    "                        framework_version=\"1.3-1\",\n",
    "                        base_job_name=training_job_name_prefix\n",
    "                    )\n",
    "# Setting the input channels for tuning job\n",
    "s3_input_train = TrainingInput(s3_data=\"s3://{}/{}\".format(read_bucket, train_data_key), content_type=\"csv\", s3_data_type=\"S3Prefix\")\n",
    "s3_input_validation = (TrainingInput(s3_data=\"s3://{}/{}\".format(read_bucket, validation_data_key), \n",
    "                                    content_type=\"csv\", s3_data_type=\"S3Prefix\")\n",
    "                      )\n",
    "\n",
    "xgb_estimator_base.fit(inputs={\"train\": s3_input_train, \"validation\": s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66c3a9a2-0379-4fb2-a98f-b131e85aeddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate(s3_input_test, model):\n",
    "    data_test = pd.read_csv(s3_input_test)\n",
    "    label_test = pd.DataFrame(data_test[\"fraud\"])\n",
    "    test = data_test.drop(\"fraud\", axis=1)\n",
    "    dtest = xgb.DMatrix(test, label=label_test)\n",
    "    test_pred = model.predict(dtest)\n",
    "    test_auc = roc_auc_score(label_test, test_pred)\n",
    "    return test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd3dd4-1f1d-4042-a3fd-93d4a27032e2",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77020288-de68-4c7f-aeee-b0ee8d8dc3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_uri = xgb_estimator_base.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c159b0d1-6d8e-4ec4-a604-fd0f3ed36f47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-539179515961/fraud-detect-demo-dewanup/training_jobs/xgbtrain-dewanup-2023-04-03-06-06-39-282/output/model.tar.gz to tmp/model/model.tar.gz\n",
      "xgboost-model\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./tmp/model/\n",
    "!aws s3 cp $model_s3_uri ./tmp/model/model.tar.gz\n",
    "!tar -xvzf ./tmp/model/model.tar.gz -C ./tmp/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0515aef-721c-4b49-8fe8-af558060d4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test AUC for baseline model 0.82\n"
     ]
    }
   ],
   "source": [
    "s3_input_test = \"s3://{}/{}\".format(read_bucket, test_data_key)\n",
    "model = joblib.load('./tmp/model/xgboost-model')\n",
    "test_auc = evaluate(s3_input_test, model)\n",
    "print(\" Test AUC for baseline model\" ,round(test_auc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9375f72-3008-47d5-af62-b80d4d6374b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 6: Launch hyperparameter tuning jobs in script mode using SageMaker Hyperparameter tuning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c567424c-2b68-4809-bb58-2d34981b232f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m4.xlarge.\n"
     ]
    }
   ],
   "source": [
    "# SageMaker estimator\n",
    "\n",
    "# Set static hyperparameters that will not be tuned\n",
    "static_hyperparams = {  \n",
    "                        \"eval_metric\" : \"auc\",\n",
    "                        \"objective\": \"binary:logistic\",\n",
    "                        \"num_round\": \"100\"\n",
    "                      }\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "                        entry_point=\"xgboost_train.py\",\n",
    "                        output_path=estimator_output_uri,\n",
    "                        code_location=estimator_output_uri,\n",
    "                        hyperparameters=static_hyperparams,\n",
    "                        role=sagemaker_role,\n",
    "                        instance_count=train_instance_count,\n",
    "                        instance_type=train_instance_type,\n",
    "                        framework_version=\"1.3-1\",\n",
    "                        base_job_name=training_job_name_prefix\n",
    "                    )\n",
    "\n",
    "# Setting ranges of hyperparameters to be tuned\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"subsample\": ContinuousParameter(0.7, 0.95),\n",
    "    \"colsample_bytree\": ContinuousParameter(0.7, 0.95),\n",
    "    \"max_depth\": IntegerParameter(1, 8)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "# Setting up tuner object\n",
    "tuner_config_dict = {\n",
    "                     \"estimator\" : xgb_estimator,\n",
    "                     \"max_jobs\" : 5,\n",
    "                     \"max_parallel_jobs\" : 2,\n",
    "                     \"objective_metric_name\" : objective_metric_name,\n",
    "                     \"hyperparameter_ranges\" : hyperparameter_ranges,\n",
    "                     \"base_tuning_job_name\" : tuning_job_name_prefix,\n",
    "                     \"strategy\" : \"Random\"\n",
    "                    }\n",
    "tuner = HyperparameterTuner(**tuner_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f2805-dfac-4b91-bb06-6bac8446417e",
   "metadata": {},
   "source": [
    "#### [Note 1]: Below cell ⬇️ will take about 7 mins to run as it tries to tune multiple parameters ( each dot indicates running state and ! indicates completion of the job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194ad84-d2b9-4f5f-a012-eac402fc889c",
   "metadata": {},
   "source": [
    "#### [Note 2] You can head over to Sagemaker Console -> Hyperparameter tuning jobs to view the progress of the launched tuning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e35ecbf5-4b6c-45fb-b52c-b5a2a0330752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: xgbtune-dewanup-230403-0612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Setting the input channels for tuning job\n",
    "s3_input_train = TrainingInput(s3_data=\"s3://{}/{}\".format(read_bucket, train_data_key), content_type=\"csv\", s3_data_type=\"S3Prefix\")\n",
    "s3_input_validation = (TrainingInput(s3_data=\"s3://{}/{}\".format(read_bucket, validation_data_key), \n",
    "                                    content_type=\"csv\", s3_data_type=\"S3Prefix\")\n",
    "                      )\n",
    "\n",
    "tuner.fit(inputs={\"train\": s3_input_train, \"validation\": s3_input_validation}, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06885aa-7fca-4aeb-bd80-efb77578f1aa",
   "metadata": {},
   "source": [
    "### Analyzing Tuner results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a875407c-466f-4cf1-b115-0fd0426ecc83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>subsample</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859696</td>\n",
       "      <td>0.319158</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.913080</td>\n",
       "      <td>xgbtune-dewanup-230403-0612-005-a64cd0c3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2023-04-03 06:17:13+00:00</td>\n",
       "      <td>2023-04-03 06:17:50+00:00</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.750360</td>\n",
       "      <td>0.319645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.722313</td>\n",
       "      <td>xgbtune-dewanup-230403-0612-001-50ef28ba</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2023-04-03 06:14:08+00:00</td>\n",
       "      <td>2023-04-03 06:15:55+00:00</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.879701</td>\n",
       "      <td>0.482695</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.874829</td>\n",
       "      <td>xgbtune-dewanup-230403-0612-004-b7783d97</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2023-04-03 06:16:32+00:00</td>\n",
       "      <td>2023-04-03 06:17:04+00:00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.709801</td>\n",
       "      <td>0.653393</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.857024</td>\n",
       "      <td>xgbtune-dewanup-230403-0612-003-7457e134</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2023-04-03 06:16:25+00:00</td>\n",
       "      <td>2023-04-03 06:17:02+00:00</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815706</td>\n",
       "      <td>0.103396</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.839529</td>\n",
       "      <td>xgbtune-dewanup-230403-0612-002-1d2d6601</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2023-04-03 06:14:36+00:00</td>\n",
       "      <td>2023-04-03 06:16:18+00:00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colsample_bytree       eta  max_depth  subsample  \\\n",
       "0          0.859696  0.319158        2.0   0.913080   \n",
       "4          0.750360  0.319645        2.0   0.722313   \n",
       "1          0.879701  0.482695        7.0   0.874829   \n",
       "2          0.709801  0.653393        4.0   0.857024   \n",
       "3          0.815706  0.103396        7.0   0.839529   \n",
       "\n",
       "                            TrainingJobName TrainingJobStatus  \\\n",
       "0  xgbtune-dewanup-230403-0612-005-a64cd0c3         Completed   \n",
       "4  xgbtune-dewanup-230403-0612-001-50ef28ba         Completed   \n",
       "1  xgbtune-dewanup-230403-0612-004-b7783d97         Completed   \n",
       "2  xgbtune-dewanup-230403-0612-003-7457e134         Completed   \n",
       "3  xgbtune-dewanup-230403-0612-002-1d2d6601         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0                 0.83 2023-04-03 06:17:13+00:00 2023-04-03 06:17:50+00:00   \n",
       "4                 0.80 2023-04-03 06:14:08+00:00 2023-04-03 06:15:55+00:00   \n",
       "1                 0.75 2023-04-03 06:16:32+00:00 2023-04-03 06:17:04+00:00   \n",
       "2                 0.72 2023-04-03 06:16:25+00:00 2023-04-03 06:17:02+00:00   \n",
       "3                 0.71 2023-04-03 06:14:36+00:00 2023-04-03 06:16:18+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                        37.0  \n",
       "4                       107.0  \n",
       "1                        32.0  \n",
       "2                        37.0  \n",
       "3                       102.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of tuning results ordered in descending order of performance\n",
    "df_tuner = sagemaker.HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.job_name).dataframe()\n",
    "df_tuner = df_tuner[df_tuner[\"FinalObjectiveValue\"]>-float('inf')].sort_values(\"FinalObjectiveValue\", ascending=False)\n",
    "df_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9162f-00ad-4b12-8717-20efc3926f01",
   "metadata": {},
   "source": [
    "### UI to Check: 📺\n",
    "    - Experiments -> Hyperparameter Tuning Job / SM Hyperparameter Training Console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8134cda-658e-4d9d-a905-10e0d0bc3dff",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate the Hyperparameter Tuner Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "442d5af0-bd62-4c6f-a8eb-b20d6596b800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_train_job_name = tuner.best_training_job()\n",
    "model_s3_uri = estimator_output_uri + '/' + best_train_job_name + '/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3b6195a-5bf3-42ca-8895-aa1f7a4fa33d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-539179515961/fraud-detect-demo-dewanup/training_jobs/xgbtune-dewanup-230403-0612-005-a64cd0c3/output/model.tar.gz to tmp/hpo-model/model.tar.gz\n",
      "xgboost-model\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./tmp/hpo-model/\n",
    "!aws s3 cp $model_s3_uri ./tmp/hpo-model/model.tar.gz\n",
    "!tar -xvzf ./tmp/hpo-model/model.tar.gz -C ./tmp/hpo-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f82d30d8-b85a-4a68-affc-ae4f351c9683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test AUC for baseline model 0.84\n"
     ]
    }
   ],
   "source": [
    "s3_input_test = \"s3://{}/{}\".format(read_bucket, test_data_key)\n",
    "model = joblib.load('./tmp/hpo-model/xgboost-model')\n",
    "test_auc = evaluate(s3_input_test, model)\n",
    "print(\" Test AUC for baseline model\" ,round(test_auc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e9b59-fdf4-4653-8528-a79c823a4dc2",
   "metadata": {},
   "source": [
    "# Step 8: Deploy the Model using SM Endpoints for further inference testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65a2a04d-d5da-404f-abd1-f779bc0573d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: fraud-detect-xgb-model-dewanup\n"
     ]
    }
   ],
   "source": [
    "tuner_job_info = sagemaker_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)\n",
    "\n",
    "model_matches = sagemaker_client.list_models(NameContains=xgb_model_name)[\"Models\"]\n",
    "\n",
    "if not model_matches:\n",
    "    _ = sess.create_model_from_job(\n",
    "            name=xgb_model_name,\n",
    "            training_job_name=tuner_job_info['BestTrainingJob'][\"TrainingJobName\"],\n",
    "            role=sagemaker_role,\n",
    "            image_uri=tuner_job_info['TrainingJobDefinition'][\"AlgorithmSpecification\"][\"TrainingImage\"]\n",
    "            )\n",
    "else:\n",
    "\n",
    "    print(f\"Model {xgb_model_name} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "31a55823-2bf6-4864-87db-a22c9adf8b85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating model with name: xgb-fraud-model-dev-dewanup\n",
      "INFO:sagemaker:Creating endpoint-config with name xgb-fraud-model-dev-dewanup-2023-04-03-06-19-11-018\n",
      "INFO:sagemaker:Creating endpoint with name xgb-fraud-model-dev-dewanup-2023-04-03-06-19-11-018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!\n",
      "Model deployed at endpoint : xgb-fraud-model-dev-dewanup-2023-04-03-06-19-11-018\n"
     ]
    }
   ],
   "source": [
    "best_train_job_name = tuner.best_training_job()\n",
    "\n",
    "model_path = estimator_output_uri + '/' + best_train_job_name + '/output/model.tar.gz'\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "create_model_config = {\"model_data\":model_path,\n",
    "                       \"role\":sagemaker_role,\n",
    "                       \"image_uri\":training_image,\n",
    "                       \"name\":endpoint_name_prefix,\n",
    "                       \"predictor_cls\":sagemaker.predictor.Predictor\n",
    "                       }\n",
    "# Create a SageMaker model\n",
    "model = sagemaker.model.Model(**create_model_config)\n",
    "\n",
    "# Deploy the best model and get access to a SageMaker Predictor\n",
    "predictor = model.deploy(initial_instance_count=predictor_instance_count, \n",
    "                         instance_type=predictor_instance_type,\n",
    "                         serializer=CSVSerializer(),\n",
    "                         deserializer=CSVDeserializer())\n",
    "print(f\"\\nModel deployed at endpoint : {model.endpoint_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e51b7c2-4c5f-4670-86f1-fed3da6c1eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction : 0, True label : 0\n"
     ]
    }
   ],
   "source": [
    "# Sample test data\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "payload = test_df.drop([\"fraud\"], axis=1).iloc[10].to_list()\n",
    "print(f\"Model prediction : {int(float(predictor.predict(payload)[0][0]))}, True label : {test_df['fraud'].iloc[10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98673729-0871-42ee-adee-3423a3c0321e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
